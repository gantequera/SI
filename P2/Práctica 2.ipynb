{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1w-sVA-h82d"
      },
      "source": [
        "# Práctica 2: clasificación de dígitos MNIST mediante AdaBoost\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1hbMxmiiHWI"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "En esta práctica se ha desarrollado un sistema para distinguir dígitos manuscritos del 0 al 9 en imagenes. El sistema implementado es de aprendizaje supervisado con AdaBoost. El objetivo de la práctica es entrenar al sistema, mediante un conjunto de imagenes de prueba, para clasificar imagenes en estas clases (dígitos del 0 al 9) aunque no hayan sido previamente analizadas por el sistema.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1CI-5CzMDSAiKRN8bE3MAniHjkVL3fDWn\" width=500>\n",
        "\n",
        "El banco de imagenes utilizado para las pruebas es la base de datos MNIST "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12Jm82LuM4D8"
      },
      "source": [
        "Lo primero será importar las librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qPgdzozKxsJi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "import random, math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fabseaAOf3da"
      },
      "source": [
        "Desde la libería de Keras podemos descargar la base datos MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObCTezA8gHOb",
        "outputId": "5f2aa8dd-09c9-482b-ae5b-81764a8b3b8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train.shape,y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMWE3hpqgs3c"
      },
      "source": [
        "Podemos guardar la base de datos en un fichero con el siguiente comando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UwZhUZfpg2bd"
      },
      "outputs": [],
      "source": [
        "np.savez(\"mnist\",x=x_train,y=y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhvNEctdiV2W"
      },
      "source": [
        "La cargamos para utilizarla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAHczaleib5u",
        "outputId": "61f8643b-f7f2-4dd9-d87b-ab0f07267b55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "npzfile = np.load(\"mnist.npz\")\n",
        "mnist_X = npzfile['x']\n",
        "mnist_Y = npzfile['y']\n",
        "mnist_X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTGcqWYwgSoJ"
      },
      "source": [
        "Veamos alguna de las imagenes del banco de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "YmnDV3RigY6T",
        "outputId": "e5822736-f5ba-480a-f578-54ea81a5f8a1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Etiqueta: 3\n"
          ]
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.imshow(mnist_X[1007])\n",
        "plt.show()\n",
        "print(\"Etiqueta: \" + str(mnist_Y[1007]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANntXnhohkHd"
      },
      "source": [
        "### Implementación AdaBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yt22wELipJT"
      },
      "source": [
        "Adaptación de los arrays de imágenes y etiquetas para AdaBoost en función de la clase para la que se va a entrenar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNnU_E8dinOz",
        "outputId": "1c8485d0-925c-4c44-aded-eb48e8e7cbd4"
      },
      "outputs": [],
      "source": [
        "DIV = 10000\n",
        "TEST = 20000\n",
        "\n",
        "def adaptar_conjuntos(mnist_X, mnist_Y, clase):\n",
        "    X = mnist_X[:DIV].reshape(DIV, 784)\n",
        "\n",
        "    Y = []\n",
        "    for i in range(len(mnist_Y[:DIV])):\n",
        "        if mnist_Y[i] == clase:\n",
        "            Y.append(1)\n",
        "        else:\n",
        "            Y.append(-1)\n",
        "    \n",
        "    return (X, Y)\n",
        "\n",
        "\n",
        "def adaptar_conjuntos_test(mnist_X, mnist_Y):\n",
        "    X = mnist_X.copy()\n",
        "    X = np.reshape(X[DIV:TEST], (TEST - DIV, 784))\n",
        "\n",
        "    return (X, mnist_Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY5RX87hizst"
      },
      "source": [
        "Funciones necesarias para los clasificadores débiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JPzp9OSAi8rj"
      },
      "outputs": [],
      "source": [
        "def generar_clasificador_debil(dimension_datos):\n",
        "    return (random.randint(0, dimension_datos-1), random.randint(0, 255), random.choice((-1, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OZccF64ljbUr"
      },
      "outputs": [],
      "source": [
        "def aplicar_clasificador_debil(clasificador, imagen):\n",
        "    v = imagen[:,clasificador[0]]\n",
        "    return ((v >= clasificador[1]) * 1 + (v < clasificador[1]) * -1) * clasificador[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "M50DGeNhjgDk"
      },
      "outputs": [],
      "source": [
        "def obtener_error(clasificador, X, Y, D):\n",
        "    return D * (aplicar_clasificador_debil(clasificador, X) != Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cotcuFUsjtve"
      },
      "source": [
        "Función de entrenamiento adaboost que nos permite obtener un conjunto de clasificadores fuertes y sus respectivos valores $\\alpha$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "paE5m0hhjwyX"
      },
      "outputs": [],
      "source": [
        "def adaboost(X, Y, T, A):\n",
        "    clasificadores_debiles = []\n",
        "    alphas = []\n",
        "    D = np.full(len(X), 1.0/len(X))\n",
        "\n",
        "    for t in range(T):\n",
        "        conjuntos = []\n",
        "        for k in range(A):\n",
        "            c_d = generar_clasificador_debil(28*28)                  # Obtenemos un clasificador debil\n",
        "            clas = aplicar_clasificador_debil(c_d, X)         # Guardamos las clasificaciones de las imagenes\n",
        "            eps = np.sum(obtener_error(c_d, X, Y, D))      # Calculamos el error \n",
        "            conjuntos.append((c_d, eps, clas))\n",
        "        pri = True\n",
        "        for elem in conjuntos:\n",
        "            if pri:\n",
        "                fc = elem\n",
        "                pri = False\n",
        "                continue\n",
        "            if elem[1] < fc[1]:           # Guardamos el conjunto con menor error\n",
        "                fc = elem  \n",
        "        alph = 0.5*math.log2((1-fc[1])/fc[1])\n",
        "        alphas.append(alph)\n",
        "        clasificadores_debiles.append(fc[0])\n",
        "\n",
        "        Z = np.sum(D)\n",
        "        for i in range(len(D)):\n",
        "            D[i] = (D[i]*(math.e**(-alph*Y[i] * fc[2][i])))/Z\n",
        "        \n",
        "    return (clasificadores_debiles, alphas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Función para aplicar nuestro clasificador fuerte una vez se ha entrenado. Esta función nos permite obtener, para una imagen, el valor que tiene en una clase, según los clasificadores debiles de esta clase ponderados por su $\\alpha$. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def aplicar_clasificador_fuerte(clasificadores, alphas, imagen):\n",
        "    clasificacion = 0\n",
        "    for i in range(len(clasificadores)):\n",
        "        clasificacion += alphas[i] * aplicar_clasificador_debil(clasificadores[i], np.array([imagen]))\n",
        "\n",
        "    return clasificacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Además se ha implementado una función que entrena el sistema para las 10 clases haciendo uso de la función adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def entrenar_sistema(mnist_X, mnist_Y, T, A):\n",
        "    clasificadores = []\n",
        "    alphas = []\n",
        "    for clase in range(10):\n",
        "        (trainX, trainY) = adaptar_conjuntos(mnist_X, mnist_Y, clase)\n",
        "        (cl, al) = adaboost(trainX, trainY, T, A)\n",
        "        clasificadores.append(cl)\n",
        "        alphas.append(al)\n",
        "    return (clasificadores, alphas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se ha implementado la siguiente función que permite probar para un set de imagenes, el índice de acierto que tiene el sistema para una clase concreta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def testn(X, Y, clasificadores, alphas, n):\n",
        "    correct = total = 0\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        if (Y[i] != n):\n",
        "            continue\n",
        "        total += 1\n",
        "        clasif = (-1, 0)\n",
        "        for j in range(10):\n",
        "            punt = (aplicar_clasificador_fuerte(clasificadores[j], alphas[j], X[i]))\n",
        "            if punt > clasif[1]:\n",
        "                clasif = (j, punt)\n",
        "        if n == clasif[0]: \n",
        "            correct += 1\n",
        "\n",
        "    return correct/total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Veamos una prueba para la clase '6'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proceso de entrenamiento\n",
            "Proceso de pruebas\n",
            "Porcentaje de aciertos del sistema para la clase 0: 8.875739644970414%\n"
          ]
        }
      ],
      "source": [
        "T = 10\n",
        "A = 20\n",
        "print(\"Proceso de entrenamiento\")\n",
        "(clasificadores, alphas) = entrenar_sistema(mnist_X, mnist_Y, T, A)\n",
        "(testX, testY) = adaptar_conjuntos_test(mnist_X, mnist_Y)\n",
        "print(\"Proceso de pruebas\")\n",
        "print(f\"Porcentaje de aciertos del sistema para la clase 0: {np.average(testn(testX, testY, clasificadores, alphas, 6))*100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La función testn utilizada previamente, se puede generalizar para el conjunto de clases de la siguiente forma, de modo que permite calcular el índice de acierto que tiene el sistema en su conjunto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(X, Y, clasificadores, alphas):\n",
        "    correct = np.full(10, 0)\n",
        "    total = np.full(10, 0)\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        total[Y[i]] += 1\n",
        "        clasif = (-1, 0)\n",
        "        for j in range(10):\n",
        "            punt = (aplicar_clasificador_fuerte(clasificadores[j], alphas[j], X[i]))\n",
        "            if punt > clasif[1]:\n",
        "                clasif = (j, punt)\n",
        "        if Y[i] == clasif[0]: \n",
        "            correct[clasif[0]] += 1\n",
        "\n",
        "    return correct/total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a realizar una prueba con valores de A y T pequeños (los definidos para el test anterior), que permita ver el funcionamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proceso de entrenamiento\n",
            "Proceso de pruebas\n",
            "Porcentaje de aciertos del sistema: 6.7731031763100304%\n"
          ]
        }
      ],
      "source": [
        "print(\"Proceso de entrenamiento\")\n",
        "(clasificadores, alphas) = entrenar_sistema(mnist_X, mnist_Y, T, A)\n",
        "(testX, testY) = adaptar_conjuntos_test(mnist_X, mnist_Y)\n",
        "print(\"Proceso de pruebas\")\n",
        "print(f\"Porcentaje de aciertos del sistema: {np.average(test(testX, testY, clasificadores, alphas))*100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHyBl9IXOSQL"
      },
      "source": [
        "Para realizar un análisis que ayude a determinar los valores adecuados para T y A se ha utilizado la siguiente función"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def valorarAT(X, Y, A, T, At, Ta):\n",
        "    resultsA = []\n",
        "    for i in At:\n",
        "        (clasificadores, alphas) = entrenar_sistema(X, Y, T, i)\n",
        "        (testX, testY) = adaptar_conjuntos_test(X, Y)\n",
        "        resultsA.append(test(testX, testY, clasificadores, alphas))    \n",
        "\n",
        "    resultsT = []\n",
        "    for i in Ta:\n",
        "        (clasificadores, alphas) = entrenar_sistema(X, Y, i, A)\n",
        "        (testX, testY) = adaptar_conjuntos_test(X, Y)\n",
        "        resultsT.append(test(testX, testY, clasificadores, alphas))\n",
        "    return (resultsA, resultsT) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En esta función se entrena el sistema en función de los valores de `At` con T constante, y se obtienen los resultados para cada uno de estos entrenamientos. Despues s ehace lo propio pero para cada valor de `Ta` con A constante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xox0oiq8pI5G"
      },
      "source": [
        "# Cuestiones sobre la práctica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explica brevemente cómo has adaptado la base datos MNIST al algoritmo AdaBoost\n",
        "\n",
        "Para adaptar los elementos de la base de datos de MNIST al algoritmo de entrenamiento, se ha utilizado la función `adaptar_conjuntos` formulada previamente. Esta función consiste en darle una nueva forma a cada imagen. Por defecto las imágenes de MNIST son de 28x28 píxeles, pero en esta función se estreuctura de forma que sean un único vector con los 784 píxeles seguidos, de forma que sea más sencillo de acceder a cada píxel individual. También se han editado las etiquetas, poniendo los valores 1, si es la clase a entrenar, y -1 en caso contrario. Por este motivo, para cada clase a entrenar, se debe adaptar de nuevo los datos. Además, del conjunto total de imagenes se han seleccionado para entrenar, las primeras 20000.\n",
        "\n",
        "Por otro lado, se han tenido que adaptar también estos datos al algoritmo de prueba, con la función `adaptar_conjuntos_test`. En este caso, para adaptar las imagenes, se hace del mismo modo. La diferencia recae en las etiquetas, las cuales se quedan tal cual está en la base de datos. Para el conjunto de datos de testeo se han utilizado las siguientes 10000 imagenes, esto es, de la 20001 a la 30000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqBNtxycrYz-"
      },
      "source": [
        "## Comenta detalladamente el funcionamiento de AdaBoost teniendo en cuenta que tasa media de fallos obtienes para aprendizaje y test. Correlaciona los porcentajes de acierto y de fallo con los valores de A y de T.\n",
        "\n",
        "AdaBoost es un algoritmo mediante el cual obtener clasificadores fuertes a través de un entrenamiento. Cuenta con dos parámetros importantes, A y T. A define el número de clasificadores aleatorios que vamos a obtener para probar y obtener un clasificador débil. El parámetro T por otro lado, indica el número de clasificadores débiles que compondrán nuestro clasificador fuerte.\n",
        "\n",
        "Con la función `valorarAT` definida previamente, se tratará de ver que papel cumplen A y T en la precisión del sistema. Para ello lanzaremos la siguiente prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "T = 10\n",
        "A = 300\n",
        "At = range(100, 1301, 80)\n",
        "Ta = range(40, 321, 40)\n",
        "\n",
        "(rA, rT) = valorarAT(mnist_X, mnist_Y, A, T, At, Ta)\n",
        "rAcorr = [np.average(i) for i in rA]\n",
        "rTcorr = [np.average(i) for i in rT]\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(At, rAcorr, 'r-o')\n",
        "plt.title(f\"Precisión del sistema en función de A con T = {T}\")\n",
        "plt.savefig(\"valoA.pdf\", format=\"pdf\")\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.plot(Ta, rTcorr, 'b-o')\n",
        "plt.title(f\"Precisión del sistema en función de T con A = {A}\")\n",
        "plt.savefig(\"valoT.pdf\", format=\"pdf\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Estas gráficas muestran detalles importantes de Adaboost. \n",
        "\n",
        "El primero de ellos es que existe una relación lineal entre el valor de A y T con la precisión del sistema, esto es, aumentar el valor de A o de T, aumentará el índice de aciertos del sistema. Aún así, vemos que esta relación no es estricta, es decir, vemos que en algunas pruebas con valores de A mayores, obtenemos un acierto menor. Esto se debe a que el modo de obtener clasificadores es aleatorio, y aún siendo cierto que a mayor número de clasificadores probados, aumentará la fiabilidad, no es seguro que el clasificador final sea mejor que uno obtenido con menor valor de A. Respecto a T vemos que la precisión parece estancarse en cierto punto.\n",
        "\n",
        "El segundo detalle es la influencia de A y T en la gráfica de precisión. El valor de A es el que da estabilidad a la gráfica para diferentes valores de T, pues al aumentar A se reduce la aleatoriedad del clasificador y viceversa. Por otro lado, el valor de T desplaza la curva para diferentes valores de A verticalmente, esto es, a mayor valor de T, veríamos unos mayores porcentajes de acierto y a la inversa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78BStUb3sdQF"
      },
      "source": [
        "## ¿Cómo afecta el número de clasificadores generados al tiempo empleado para el proceso de aprendizaje? ¿Qué importancia le darías? Justifica tu respuesta. \n",
        "\n",
        "El tiempo de aprendizaje del algoritmo depende linealmente de básicamente tres variables, que son, el número de clasificadores débiles a obtener (T), los clasificadores débiles aleatorios por cada iteración (A) y la cántidad de imagenes utilizadas (X). No modificando A ni X, el tiempo de aprendizaje dependerá linealmente de T, esto es, aumentar el valor de T en una proporción hará aumentar el tiempo destinado al aprendizaje en esta misma proporción. \n",
        "\n",
        "A mayor número de clasificadores débiles entrenemos en nuestro algoritmo, obtendremos unos resultados mejores, esto es un porcentaje de acierto mayor. A pesar de ser cierto esto, el incremento de precisión del sistema no es lineal con el incremento de T, sino que más bien describe una función $log(T)$. Es por esto que no se puede escoger un número muy elevado para T, pues mientras el tiempo de entrenamiento crece linealmente con T, la precisión acaba estancandose.\n",
        "\n",
        "Resumiendo, debe escogerse un número de T apropiado al problema y a la precisión necesaria en este caso, teniendo en cuenta el tiempo disponible para el entrenamiento, y para obtener este valor de T, lo apropiado es realizar numerosas pruebas en las que se prueben diversos valores para escoger de entre estos el que consideremos óptimo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7byGnWju4DA"
      },
      "source": [
        "## ¿Cómo has dividido los datos en conjunto de entrenamiento y test? ¿Para qué es útil hacer esta división? \n",
        "\n",
        "Los diferentes conjuntos se han dividido a través de las dos funciones diferentes de adaptar conjuntos. En estas funciones se han definido unos valores `DIV` y `TEST` que permiten dividirlos. Para el conjunto de entrenamiento se han utilizado las primerass `DIV` imagenes de mnist, y para el test se han utilizado desde la imagen `DIV` hasta la imagen `TEST`.\n",
        "\n",
        "No solo es útil hacer esta división, es necesario para hacer un test riguroso del sistema. Si utilizaramos las imagenes de entrenamiento en el test, obtendriamos resultados muy elevados de precisión, pues es con estas mismas imágenes con las que el sistema ha aprendido a diferenciar. Al utilizar otras imagenes, la fialidad del sistema bajará mucho, y es por esto que en ese se deberá utilizar mayores valores de A y T."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lgvdtFkvcCm"
      },
      "source": [
        "## ¿Has observado si se produce sobre entrenamiento? Justifica tu respuesta con una gráfica en la que se compare el error de entrenamiento y el de test a lo largo de las ejecuciones. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3z6ssR5wMXO"
      },
      "source": [
        "## ¿Cómo has conseguido que Adaboost clasifique entre los 10 dígitos cuando solo tiene una salida binaria?\n",
        "\n",
        "Al utilizar adaboost se obtiene un conjunto de clasificadores débiles para una clase con salida binaria. Estos clasificadores débiles componen un clasificador fuerte, que nos permite obtener un valor al ponderar cada uno de estos clasificadores débiles con su valor $\\alpha$.\n",
        "\n",
        "A partir de esta idea, si se lanza el algoritmo Adaboost para cada una de las clases, obtendremos un clasificador fuerte para cada clase. A partir de este 'sistema' de clasificadores, es posible, para una imagen, al aplicar cada uno de estos clasificadores fuertes, que devolverán valores numéricos, determinar a qué clase pertenece la imagen con el valor del clasifiador más alto. Por ejemplo, si para una imagen cualquiera se aplican los clasificadores del sistema, y obtenemos los valores para la clase 0 = 2.45 y para la clase 7 = 3.12, el sistema dirá que esta imagen contiene un 7."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ampliación Julio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ¿Varía T y A entre ambos clasificadores débiles al usarlos en Adaboost? ¿Cuál requiere un T más elevado? ¿Porqué?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ¿Qué clasificador débil crees que funciona mejor para clasificar un dígito? ¿Y el problema completo con 10 dígitos?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Curso2021P2-Alumnos.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "4caea23604fddfff4af07b124ceffffee3f6d283b9045457928205b8f8752d07"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
